<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Python," />





  <link rel="alternate" href="/atom.xml" title="Chen's Alchemy" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="通过上一篇博客的工作，我们拥有了一个简单爬虫。但确实有点简陋的过分了，要啥啥没有，所以今天主要就是简单讲解一下爬虫的解析流程与爬取结果的输出形式。新任务获得：粗解爬虫解析流程并设置爬取结果的输出">
<meta property="og:type" content="article">
<meta property="og:title" content="Crawl Web Content - 粗解爬虫解析流程及结果输出">
<meta property="og:url" content="https://millionaryearl.github.io/2016/10/08/python-Scrapy-parser/index.html">
<meta property="og:site_name" content="Chen's Alchemy">
<meta property="og:description" content="通过上一篇博客的工作，我们拥有了一个简单爬虫。但确实有点简陋的过分了，要啥啥没有，所以今天主要就是简单讲解一下爬虫的解析流程与爬取结果的输出形式。新任务获得：粗解爬虫解析流程并设置爬取结果的输出">
<meta property="og:image" content="https://cl.ly/3h3F0j1d1P0s/python_2_1.png">
<meta property="og:image" content="https://cl.ly/3S1k1Z3k3q1i/comic_success_kid.jpg">
<meta property="og:updated_time" content="2016-10-09T07:44:28.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Crawl Web Content - 粗解爬虫解析流程及结果输出">
<meta name="twitter:description" content="通过上一篇博客的工作，我们拥有了一个简单爬虫。但确实有点简陋的过分了，要啥啥没有，所以今天主要就是简单讲解一下爬虫的解析流程与爬取结果的输出形式。新任务获得：粗解爬虫解析流程并设置爬取结果的输出">
<meta name="twitter:image" content="https://cl.ly/3h3F0j1d1P0s/python_2_1.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="https://millionaryearl.github.io/2016/10/08/python-Scrapy-parser/"/>

  <title> Crawl Web Content - 粗解爬虫解析流程及结果输出 | Chen's Alchemy </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Chen's Alchemy</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">iOS Notes</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Crawl Web Content - 粗解爬虫解析流程及结果输出
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-08T16:29:15+08:00" content="2016-10-08">
              2016-10-08
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Scrapy/" itemprop="url" rel="index">
                    <span itemprop="name">Scrapy</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/08/python-Scrapy-parser/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/10/08/python-Scrapy-parser/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>通过上一篇博客的工作，我们拥有了一个简单爬虫。但确实有点简陋的过分了，要啥啥没有，所以今天主要就是简单讲解一下爬虫的解析流程与爬取结果的输出形式。<br><strong><em>新任务获得：粗解爬虫解析流程并设置爬取结果的输出</em></strong></p>
<a id="more"></a>
<h2 id="抓取流程"><a href="#抓取流程" class="headerlink" title="抓取流程"></a>抓取流程</h2><p><img src="https://cl.ly/3h3F0j1d1P0s/python_2_1.png" alt=""><br>实际上爬虫的工作流程很是直白的。首先找到包含目标信息的网站的网址，写入爬虫文件的<code>start_urls</code>参数，做为爬取的起始点。同时输入适当的网址到<code>allowed_domains</code>参数，来约束爬取的范围。</p>
<p>第二步是爬取到网站内容，这个内容基本上会以<code>HTML&amp;CSS</code>格式呈现，这一步<code>scrapy</code>会帮我们做的，通常我们只需要运行爬虫就可以了，应对一个复杂要求(例如：应对网站反爬取设置)可以在<code>/settings.py</code>文件里配置爬虫参数。感兴趣的可以<a href="https://doc.scrapy.org/en/latest/topics/settings.html" target="_blank" rel="external">正面上我</a></p>
<p>第三步是过滤抓取内容，以获得我们需要的信息。这个要求我们在运行爬虫之前制定好过滤规则，然后在运行爬虫时<code>scrapy</code>会直接使用</p>
<p>最后一步就是输出了，无论是直接以log形式在命令行里输出，还是保存到文件里，亦或是直接输入数据库都可以.</p>
<p>至此我们今天的任务就明确了，主要是讲解下在第三步和第四步要怎么做。<br><strong><em>任务更新：合理制定爬虫过滤规则与爬虫输出设置</em></strong></p>
<h2 id="制定爬虫过滤规则"><a href="#制定爬虫过滤规则" class="headerlink" title="制定爬虫过滤规则"></a>制定爬虫过滤规则</h2><p>因为每个抓取站点的h5文件结构都不一样，所以爬虫的可重用性比较低。对于不同的抓取目标，我们需要制定不同的抓取语句。一般的制定流程是先查阅目标站的H5结构，进而定制对应的抓取结构，最后编写抓取语句。</p>
<h3 id="查阅目标站点H5结构"><a href="#查阅目标站点H5结构" class="headerlink" title="查阅目标站点H5结构"></a>查阅目标站点H5结构</h3><ol>
<li><p>在命令行里查看<br> 使用<code>Scrapy</code>的<code>fetch</code>函数就可以直接现实H5文件结构</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scrapy fetch http://www.biquge.tw/0_972/</div></pre></td></tr></table></figure>
</li>
<li><p>在浏览器里查看<br>这个么更直接，在浏览器里打开目标地址，然后进入开发者模式，显示网页源文件就可以看到了</p>
</li>
</ol>
<h3 id="定制抓取机制"><a href="#定制抓取机制" class="headerlink" title="定制抓取机制"></a>定制抓取机制</h3><p>这个么需要一定的H5和CSS基本知识，一点都不懂的可以去<a href="http://www.w3school.com.cn" target="_blank" rel="external">W3CSchool</a>上了解一下。例如我的目标信息是：小说章节的名称与链接地址。在刚才得到的H5结构文件里，查找对应的数据单元：</p>
<pre><code>&lt;dd&gt; &lt;a style=&quot;&quot; href=&quot;/0_972/4743476.html&quot;&gt;第一千五百九十五章 黑暗现象&lt;/a&gt;&lt;/dd&gt;
</code></pre><p>可以看到我们需要的信息是存在于<code>&lt;dd&gt;&lt;/dd&gt;</code>标签内的一个<code>&lt;a&gt;</code>标签里的。所以我们需要的抓取机制应该是：</p>
<ul>
<li><strong>先筛选出所有的<code>&lt;dd&gt;&lt;/dd&gt;</code>标签</strong></li>
<li><strong>然后抓取之中的<code>&lt;a&gt;</code>标签下的<code>title</code>和<code>href</code>两个属性下的数据</strong></li>
</ul>
<p>那有人可能就会问了，明明我们需要的目标信息的最小标签单元是<code>&lt;a&gt;</code>标签,为什么要多此一举的先去筛选出上一级的<code>&lt;dd&gt;&lt;/dd&gt;</code>标签？那是因为网页里有很多其他的<code>&lt;a&gt;</code>标签，但它们的信息并非小说的章节信息，为了过滤掉这些合规却又不是有效信息的<code>&lt;a&gt;</code>标签内容，我们需要加入额外的筛选条件－上一级的<code>&lt;dd&gt;&lt;/dd&gt;</code>标签。</p>
<pre><code>&lt;li&gt;&lt;a href=&quot;/nweph.html&quot;&gt;排行榜单&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/quanben/&quot;&gt;完本小说&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a rel=&quot;nofollow&quot; href=&quot;/jilu.php&quot;&gt;阅读记录&lt;/a&gt;&lt;/li&gt;
</code></pre><h3 id="编写抓取语句"><a href="#编写抓取语句" class="headerlink" title="编写抓取语句"></a>编写抓取语句</h3><p>这个抓取语句主要是写在爬虫文件中的”parse”函数里。这里我们打开<code>fiction/spiders/biquge.py</code>文件并编辑如下</p>
<pre><code># -*- coding: utf-8 -*-  
from scrapy.spiders import Spider
from scrapy.selector import Selector
from fiction.items import FictionItem

class BiqugeSpider(Spider):
    name = &quot;biquge&quot;
    allowed_domains = [&quot;http://www.biquge.tw/&quot;]
    start_urls = (
        &apos;http://www.biquge.tw/0_972/&apos;,
    )

    def parse(self, response):
        chapters = response.xpath(&apos;//dd&apos;)
        items = []

        for chapter in chapters:
            item = FictionItem()
            item[&apos;url&apos;] = chapter.xpath(
                &apos;a/@href&apos;).extract()
            item[&apos;title&apos;] = chapter.xpath(
                &apos;a/text()&apos;).extract()
            items.append(item)

            print item[&apos;url&apos;], item[&apos;title&apos;]

        return items
</code></pre><p>上面的代码很好理解，前两行是引入相关的<code>scrapy</code>基础类，第三行是引入我们自定义的数据结构（具体信息可以去上篇博客里查看－定义模型）. 再下来么就是我们爬虫类<code>biqugeSpider</code>，头三行的爬虫属性设置也在上篇说过了，直接看到重点<code>parse</code>函数。</p>
<p>可以看到这个函数接收到了两个外部参数, <code>self</code> 和 <code>response</code>。<code>self</code>应该就是指爬虫自己，具体有啥用处，作者只能表示今天天气不错，啊哈哈哈。而<code>response</code>参数就是上述<code>抓取流程－第二步</code>抓取到全部网站内容，它应该是和上述<code>定制爬虫过滤规则－查阅目标站点H5结构</code>里看到的内容一致。</p>
<p>接下来就如上述<code>定制爬虫过滤规则－定制抓取机制</code>计划的一样，先过滤出所有的<code>&lt;dd&gt;&lt;/dd&gt;</code>标签内容，并建立一个空数组用以将来存储标签对象<code>Fiction</code>。再接下来建立一个<code>for</code>循环，从每段<code>&lt;dd&gt;&lt;/dd&gt;</code>标签内容里，进一步过滤出<code>url</code>和<code>title</code>字段信息，并存入新建的<code>Fiction</code>对象，加入到<code>items</code>结果数组里，同时在命令行里输出<code>url</code>和<code>title</code>结果。 最后在<code>for</code>循环结束后，返回<code>items</code>结果数组(这个暂时没有，稍后我们配置结果输出到json文件时会用到)</p>
<h3 id="数据提取机制"><a href="#数据提取机制" class="headerlink" title="数据提取机制"></a>数据提取机制</h3><p>虽然说知道了这段代码是怎么工作的，但具体怎么写不知道啊，到底怎么样才能从HTML源码中提取数据呢？其实有些库是可以做到的：</p>
<ul>
<li><a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="external">BeautifulSoup</a> 是在程序员间非常流行的网页分析库，它基于HTML代码的结构来构造一个Python对象， 对不良标记的处理也非常合理，但它有一个缺点：慢。<br>比如这些</li>
<li><a href="http://lxml.de/" target="_blank" rel="external">lxml</a> 是一个基于 <a href="http://docs.python.org/library/xml.etree.elementtree.html" target="_blank" rel="external">ElementTree</a> (不是Python标准库的一部分)的python化的XML解析库(也可以解析HTML)。</li>
</ul>
<p>但伟大的奥斯忒懦夫司机·作者曾经又说过</p>
<blockquote>
<p>作为一个菜鸡程序员，要有菜鸡程序员的尊严，坚决抵制听啊没听过的东西！</p>
</blockquote>
<p>所以有啥简单点的东西呢，找找看官网还真有－<code>Seletors</code>就可以完美替代，它是<code>Scrapy</code>自己提供的数据提取机制，可以通过特定的<code>XPath</code>和<code>CSS</code>表达式来选择 HTML文件中的某个部分。本篇作者就是用的这种提取机制，例如：</p>
<pre><code>response.xpath(&apos;//dd&apos;) //提取网页内容里的所有&lt;dd&gt;&lt;/dd&gt;标签内容
...
chapter.xpath(&apos;a/@href&apos;).extract() //提取chapther中&lt;a&gt;标签的@href属性
chapter.xpath(&apos;a/text()&apos;).extract() //提取chapther中&lt;a&gt;标签的text值
</code></pre><p>更多的<code>Seletor</code>提取讲解，可以<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html#topics-selectors-ref" target="_blank" rel="external">正面上我</a></p>
<h2 id="设置爬虫输出设置"><a href="#设置爬虫输出设置" class="headerlink" title="设置爬虫输出设置"></a>设置爬虫输出设置</h2><p>至此我们的爬虫可以说已经是大功告成，但数据抓是抓到了，怎么输出来用呢。大概是有三个方向：</p>
<h3 id="直接以log形式在命令行里输出"><a href="#直接以log形式在命令行里输出" class="headerlink" title="直接以log形式在命令行里输出"></a>直接以log形式在命令行里输出</h3><p>这个最简单了，只要在爬虫文件里的<code>parse</code>函数里，使用<code>print</code>命令把相应的信息给打出来就可以了</p>
<pre><code>print item[&apos;url&apos;], item[&apos;title&apos;]
</code></pre><h3 id="保存到文件里"><a href="#保存到文件里" class="headerlink" title="保存到文件里"></a>保存到文件里</h3><p>半自动的呢，可以在启动爬虫时，加入输出参数 <code>-o outputFileName</code>。需要注意的是<code>Scrapy</code>默认支持四种格式:<code>JSON</code>, <code>JSON lines</code>, <code>CSV</code>, <code>XML</code></p>
<pre><code>scrapy crawl fiction -o result.json 
// scrapy crawl spiderName -0 outputFileName
</code></pre><p>正规一点的呢，需要修改<code>/pipelines.py</code>文件如下：</p>
<pre><code>import json  
import codecs  
import re

class FictionPipeline(object):

def __init__(self):  
    self.file = codecs.open(&apos;cn_zhan.json&apos;, &apos;wb&apos;, encoding=&apos;utf-8&apos;) 

def process_item(self, item, spider):
    if item[&apos;title&apos;]:
        found = re.match(&apos;\S* \S*&apos;, str(item[&apos;title&apos;]))
        if found:
            print &apos;---------&apos;, item[&apos;title&apos;]
            line = json.dumps(dict(item), ensure_ascii=False) + &quot;\n&quot; 
            self.file.write(line)   
            return item
        else:
            print &quot;+++++++++ invalid chapter found ++++++++++++++++&quot;

def spider_closed(self, spider):
    self.file.close()
</code></pre><p>首先是在初始化方法里新建一个叫做<code>cn_zhan.json</code>的文件用以收纳抓取的信息，并约定它是<code>utf-8</code>格式（用来显示中文，同时打开它准备写入。第二步在<code>process_item</code>里我们根据正则表达式过滤掉不合规的<code>item</code>，并把合规的<code>item</code>（章节信息）转化成<code>json</code>语句存入之间申明的<code>cn_zhan.json</code>文件里。最后关闭这个文件。</p>
<p>定义好<code>/pipelines.py</code>文件后，我们还需要在<code>/settings.py</code>文件里启用刚定义的输送规则：</p>
<pre><code>ITEM_PIPELINES = {
    #&apos;fiction.pipelines.DuplicatesPipeline&apos;: 100,
    &apos;fiction.pipelines.FictionPipeline&apos;: 300,
}
</code></pre><p>注意在<code>/pipelines.py</code>文件里我们可以申明多个输送规则，例如这里作者还申明了一个去重原则。同时在<code>/settings.py</code>文件里启用时，<code>Scrapy</code>会依照数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内</p>
<h3 id="录入到数据库"><a href="#录入到数据库" class="headerlink" title="录入到数据库"></a>录入到数据库</h3><p>这个因为使用的数据库种类不同需要不同的配置，所以就先不讲解了，感兴趣的可以自己去狗哥一下</p>
<h2 id="尾声"><a href="#尾声" class="headerlink" title="尾声"></a>尾声</h2><p>折腾了这么久，激动人心的时刻终于到来了，打开命令行开始运行爬虫，完成之后你就可以在你的文件夹里发现抓取的结果文件了:<code>cn_zhan.json</code></p>
<pre><code>{&quot;url&quot;: [&quot;/0_972/603364.html&quot;], &quot;title&quot;: [&quot;第一章 太阳消失&quot;]}
{&quot;url&quot;: [&quot;/0_972/603365.html&quot;], &quot;title&quot;: [&quot;第二章 全球恐慌&quot;]}
{&quot;url&quot;: [&quot;/0_972/603366.html&quot;], &quot;title&quot;: [&quot;第三章 黑暗时代&quot;]}
{&quot;url&quot;: [&quot;/0_972/603367.html&quot;], &quot;title&quot;: [&quot;第四章 怪物降临&quot;]}
...
</code></pre><p>完美，破费，至此我们的爬虫应该可以说是初步成型了！诸君昌隆！<br><img src="https://cl.ly/3S1k1Z3k3q1i/comic_success_kid.jpg" alt=""></p>
<hr>
<p>This artical is avaliable under <a href="http://wtfpl2.com" target="_blank" rel="external">WTFPL-V2</a>. Generally, everyone is permitted to copy and do what the fuck you want to.<br>P.S. Even so said, your kindly declaration that inspired from this site - <a href="https://millionaryearl.github.io">Chen’s Alchemy</a> would be appreciated</p>
<hr>
<p>本文链接：<a href="https://millionaryearl.github.io/2016/10/08/python-Scrapy-parser/">https://millionaryearl.github.io/2016/10/08/python-Scrapy-parser/</a></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>我知道是不会有人点的，但万一有人想不开呢？</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="https://cl.ly/3W3I3O3t1622/wexinpay.JPG" alt="Chen Wei WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="https://cl.ly/3t1O403j2P1F/alipay.JPG" alt="Chen Wei Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag">#Python</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/09/29/python-Scrapy-framework/" rel="next" title="Crawl Web Content - 环境搭配与基础爬虫">
                <i class="fa fa-chevron-left"></i> Crawl Web Content - 环境搭配与基础爬虫
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/10/09/swift-APNS-aliyun/" rel="prev" title="Swift Notes - 阿里云推送SDK">
                Swift Notes - 阿里云推送SDK <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Chen Wei" />
          <p class="site-author-name" itemprop="name">Chen Wei</p>
          <p class="site-description motion-element" itemprop="description">Hi, I'm Chen, an iOS Engineer from China</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">7</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Millionaryearl" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2334525960/profile?topnav=1&wvr=6&is_all=1" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://dukewei.typify.io" target="_blank" title="Personal">
                  
                    <i class="fa fa-fw fa-home"></i>
                  
                  Personal
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#抓取流程"><span class="nav-number">1.</span> <span class="nav-text">抓取流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#制定爬虫过滤规则"><span class="nav-number">2.</span> <span class="nav-text">制定爬虫过滤规则</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#查阅目标站点H5结构"><span class="nav-number">2.1.</span> <span class="nav-text">查阅目标站点H5结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定制抓取机制"><span class="nav-number">2.2.</span> <span class="nav-text">定制抓取机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编写抓取语句"><span class="nav-number">2.3.</span> <span class="nav-text">编写抓取语句</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据提取机制"><span class="nav-number">2.4.</span> <span class="nav-text">数据提取机制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#设置爬虫输出设置"><span class="nav-number">3.</span> <span class="nav-text">设置爬虫输出设置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#直接以log形式在命令行里输出"><span class="nav-number">3.1.</span> <span class="nav-text">直接以log形式在命令行里输出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#保存到文件里"><span class="nav-number">3.2.</span> <span class="nav-text">保存到文件里</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#录入到数据库"><span class="nav-number">3.3.</span> <span class="nav-text">录入到数据库</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#尾声"><span class="nav-number">4.</span> <span class="nav-text">尾声</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen Wei</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'millionaryearl';
      var disqus_identifier = '2016/10/08/python-Scrapy-parser/';
      var disqus_title = "Crawl Web Content - 粗解爬虫解析流程及结果输出";
      var disqus_url = 'https://millionaryearl.github.io/2016/10/08/python-Scrapy-parser/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  <script type="text/javascript" src="/js/src/particle.js"></script>
</body>
</html>
